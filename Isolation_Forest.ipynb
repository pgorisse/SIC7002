{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.regularizers import l1\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import plotly as py\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import Data,Figure\n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler, MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training data size   : (70306, 109)\nValidation (test) data size : (18625, 109)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n0         0        181       5450     0               0       0    0   \n1         0        239        486     0               0       0    0   \n2         0        235       1337     0               0       0    0   \n3         0        219       1337     0               0       0    0   \n4         0        217       2032     0               0       0    0   \n\n   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n0                  0          1                0  ...         0          0   \n1                  0          1                0  ...         0          0   \n2                  0          1                0  ...         0          0   \n3                  0          1                0  ...         0          0   \n4                  0          1                0  ...         0          0   \n\n   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n0            0          0        0        0        0        0        1   \n1            0          0        0        0        0        0        1   \n2            0          0        0        0        0        0        1   \n3            0          0        0        0        0        0        1   \n4            0          0        0        0        0        0        1   \n\n   flag_SH  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n\n[5 rows x 110 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>src_bytes</th>\n      <th>dst_bytes</th>\n      <th>land</th>\n      <th>wrong_fragment</th>\n      <th>urgent</th>\n      <th>hot</th>\n      <th>num_failed_logins</th>\n      <th>logged_in</th>\n      <th>num_compromised</th>\n      <th>...</th>\n      <th>flag_REJ</th>\n      <th>flag_RSTO</th>\n      <th>flag_RSTOS0</th>\n      <th>flag_RSTR</th>\n      <th>flag_S0</th>\n      <th>flag_S1</th>\n      <th>flag_S2</th>\n      <th>flag_S3</th>\n      <th>flag_SF</th>\n      <th>flag_SH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>181</td>\n      <td>5450</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>239</td>\n      <td>486</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>235</td>\n      <td>1337</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>219</td>\n      <td>1337</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>217</td>\n      <td>2032</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 110 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "# attach the column names to the dataset\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "# open the csv dataset\n",
    "df = pd.read_csv(\"kddcup.data_10_percent.gz\",compression='gzip',header=None, names = col_names)\n",
    "\n",
    "# Remove smurf and neptune attacks\n",
    "df = df[df.label != 'smurf.']\n",
    "df = df[df.label != 'neptune.']\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "\n",
    "#data = df.drop(\"label\", axis=1) #labels serviront pour évaluer la qualité du modèle\n",
    "target = df[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "# One hot encoding\n",
    "cols_to_dummify = ['protocol_type','service','flag']\n",
    "data_dummy = pd.get_dummies(df, columns=cols_to_dummify, prefix=cols_to_dummify)\n",
    "target_dummy = pd.get_dummies(target)\n",
    "target_categories = target_dummy.columns\n",
    "\n",
    "# Splitting train/test\n",
    "X = data_dummy.values\n",
    "y = target_dummy.values\n",
    "RANDOM_SEED = 87 #penser a changer la seed a posteriori pour voir\n",
    "X_train, X_test = train_test_split(data_dummy, test_size=0.2, random_state = RANDOM_SEED)\n",
    "\n",
    "X_train = X_train[X_train['label'] == 'normal.' ] # Only train on normal data (no intrusion)\n",
    "# X_test = X_test[X_test['label'] == 'normal.']\n",
    "X_train = X_train.drop(['label'], axis=1)\n",
    "y_test  = X_test['label']\n",
    "X_test  = X_test.drop(['label'], axis=1)\n",
    "X_train = X_train.values\n",
    "X_test  = X_test.values\n",
    "\n",
    "# Standardize/Normalize dataset?\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print('Training data size   :', X_train.shape)\n",
    "print('Validation (test) data size :', X_test.shape)\n",
    "data_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/pierrick/anaconda3/envs/SIC7002/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:213: FutureWarning:\n\ndefault contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n\n/home/pierrick/anaconda3/envs/SIC7002/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:223: FutureWarning:\n\nbehaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e1b52359e4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IsolationForest' object has no attribute 'history'"
     ],
     "ename": "AttributeError",
     "evalue": "'IsolationForest' object has no attribute 'history'",
     "output_type": "error"
    }
   ],
   "source": [
    "# MODEL BUILDING\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# training the model\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "history = clf.fit(X_train)\n",
    "df_history = pd.DataFrame(history.history)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "# y_pred_outliers = clf.predict(X_outliers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy on train set:  0.8999943105851563\nAccuracy on test set:  0.8753288590604027\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d249f3756764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     trace0 = {'type' : 'scatter', \n\u001b[0;32m---> 11\u001b[0;31m               \u001b[0;34m'x'\u001b[0m    \u001b[0;34m:\u001b[0m \u001b[0mdf_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m               \u001b[0;34m'y'\u001b[0m    \u001b[0;34m:\u001b[0m \u001b[0mdf_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0;34m'name'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_history' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'df_history' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# EVALUATION\n",
    "\n",
    "print(\"Accuracy on train set: \", list(y_pred_train).count(1)/y_pred_train.shape[0])\n",
    "\n",
    "print(\"Accuracy on test set: \", list(y_pred_test).count(1)/y_pred_test.shape[0])\n",
    "\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "trace = []\n",
    "for label, loss in zip(['Train', 'Validation'], ['loss', 'val_loss']):\n",
    "    trace0 = {'type' : 'scatter', \n",
    "              'x'    : df_history.index.tolist(),\n",
    "              'y'    : df_history[loss].tolist(),\n",
    "              'name' : label,\n",
    "              'mode' : 'lines'\n",
    "              }\n",
    "        \n",
    "    trace.append(trace0)\n",
    "data = Data(trace)\n",
    "layout = {'title' : 'Model train-vs-validation loss', 'titlefont':{'size' : 30},\n",
    "          'xaxis' : {'title':  '<b> Epochs', 'titlefont':{ 'size' : 25}},\n",
    "          'yaxis' : {'title':  '<b> Loss', 'titlefont':{ 'size' : 25}},\n",
    "          }\n",
    "fig = Figure(data = data, layout = layout)\n",
    "    \n",
    "pyo.iplot(fig)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}